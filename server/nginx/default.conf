# to boost I/O on HDD we can disable access logs
access_log off;

# send headers in one piece, it is better than sending them one by one
tcp_nopush on;

# don't buffer data sent, good for small data bursts in real time
tcp_nodelay on;

# reduce the data that needs to be sent over network -- for testing environment
gzip on;
# gzip_static on;
gzip_min_length 10240;
gzip_comp_level 1;
gzip_vary on;
gzip_disable msie6;
gzip_proxied expired no-cache no-store private auth;
gzip_types
    # text/html is always compressed by HttpGzipModule
    text/css
    text/javascript
    text/xml
    text/plain
    text/x-component
    application/javascript
    application/x-javascript
    application/json
    application/xml
    application/rss+xml
    application/atom+xml
    font/truetype
    font/opentype
    application/vnd.ms-fontobject
    image/svg+xml;

# allow the server to close connection on non responding client, this will free up memory
reset_timedout_connection on;

# request timed out -- default 60
client_body_timeout 10;

# if client stop responding, free up memory -- default 60
send_timeout 2;

# number of requests client can make over keep-alive -- for testing environment
keepalive_requests 100000;

proxy_cache_path /cache levels=1:2 keys_zone=my_cache:10m max_size=5g inactive=60m use_temp_path=off;

upstream myapp1 {
    # The number of idle keepalive connections to an upstream server that remain open for each worker process
    keepalive 16;
    least_conn;
    server 18.236.153.95;
    server 35.85.153.118;
    server 34.209.94.236;
    server 34.221.172.242;
    server 35.167.166.60;
}

server {
    listen 80 default_server;
    location / {
        proxy_cache my_cache;
        proxy_cache_valid 200 302 10m;
        proxy_cache_valid 404      1m;
        proxy_cache_revalidate on;
        proxy_cache_lock on;
        proxy_pass http://myapp1;
    }
    location /loaderio-e83d5e3095f6a92e5dace346247bd424 {
        return 200 'loaderio-e83d5e3095f6a92e5dace346247bd424';
    }
}

# https://gist.github.com/denji/8359866
# Keepalive connections
# keepalive_requests – The number of requests a client can make over a single keepalive connection
# The default is 100, but a much higher value can be especially useful for testing with a load-generation tool, which generally sends a large number of requests from a single client
# http {
#     # cache informations about FDs, frequently accessed files
#     # can boost performance, but you need to test those values
#     open_file_cache max=200000 inactive=20s;
#     open_file_cache_valid 30s;
#     open_file_cache_min_uses 2;
#     open_file_cache_errors on;
#     # server will close connection after this time -- default 75
#     keepalive_timeout 30;

#     # number of requests client can make over keep-alive -- for testing environment
#     keepalive_requests 100000;
# }
# keepalive_disable msie6;        # disable selected browsers.

# # The number of requests a client can make over a single keepalive connection. The default is 100, but a much higher value can be especially useful for testing with a load‑generation tool, which generally sends a large number of requests from a single client.
# keepalive_requests 100000;

# # How long an idle keepalive connection remains open.
# keepalive_timeout 60;

# server will close connection after this time -- default 75
# keepalive_timeout 30;

# copies data between one FD and other from within the kernel
# faster than read() + write()
# sendfile on;
server {
    location / {
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        proxy_pass http://34.209.94.236:3000;
    }

    location /loaderio-e83d5e3095f6a92e5dace346247bd424 {
        return 200 'loaderio-e83d5e3095f6a92e5dace346247bd424';
    }
}
